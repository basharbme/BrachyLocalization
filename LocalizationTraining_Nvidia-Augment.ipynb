{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 24 ultrasound images and 24 segmentations\n"
     ]
    }
   ],
   "source": [
    "ultrasound_fullname = 'numpy_data/Stacked Arrays/Training/stacked_image_array.npy'\n",
    "segmentation_fullname = 'numpy_data/Stacked Arrays/Training/stacked_segmentation_array.npy'\n",
    "\n",
    "ultrasound_data = np.load(ultrasound_fullname)\n",
    "segmentation_data = np.load(segmentation_fullname)\n",
    "\n",
    "num_ultrasound = ultrasound_data.shape[0]\n",
    "num_segmentation = segmentation_data.shape[0]\n",
    "\n",
    "print(\"\\nFound {} ultrasound images and {} segmentations\".format(num_ultrasound, num_segmentation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test ultrasound from: numpy_data/Stacked Arrays/Test/test_image_array.npy\n",
      "Reading test segmentation from : numpy_data/Stacked Arrays/Test/test_segmentation_array.npy\n",
      "\n",
      "Found 6 test ultrasound images and 6 segmentations\n"
     ]
    }
   ],
   "source": [
    "test_ultrasound_fullname = 'numpy_data/Stacked Arrays/Test/test_image_array.npy'\n",
    "test_segmentation_fullname = 'numpy_data/Stacked Arrays/Test/test_segmentation_array.npy'\n",
    "\n",
    "print(\"Reading test ultrasound from: {}\".format(test_ultrasound_fullname))\n",
    "print(\"Reading test segmentation from : {}\".format(test_segmentation_fullname))\n",
    "\n",
    "test_ultrasound_data = np.load(test_ultrasound_fullname)\n",
    "test_segmentation_data = np.load(test_segmentation_fullname)\n",
    "\n",
    "num_test_ultrasound = test_ultrasound_data.shape[0]\n",
    "num_test_segmentation = test_segmentation_data.shape[0]\n",
    "\n",
    "print(\"\\nFound {} test ultrasound images and {} segmentations\".format(num_test_ultrasound, num_test_segmentation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "\n",
    "def random_rotation(x, rg, row_axis=1, col_axis=2, channel_axis=0,\n",
    "                    fill_mode='nearest', cval=0.):\n",
    "    # Performs a random rotation of a Numpy image tensor.\n",
    "    theta = np.pi / 180 * np.random.uniform(-rg, rg)\n",
    "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                                [np.sin(theta), np.cos(theta), 0],\n",
    "                                [0, 0, 1]])\n",
    "\n",
    "    h, w = x.shape[row_axis], x.shape[col_axis]\n",
    "    transform_matrix = transform_matrix_offset_center(rotation_matrix, h, w)\n",
    "    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n",
    "    return x\n",
    "\n",
    "\n",
    "def random_shift(x, wrg, hrg, row_axis=1, col_axis=2, channel_axis=0,\n",
    "                 fill_mode='nearest', cval=0.):\n",
    "    # Performs a random spatial shift of a Numpy image tensor.\n",
    "    h, w = x.shape[row_axis], x.shape[col_axis]\n",
    "    tx = np.random.uniform(-hrg, hrg) * h\n",
    "    ty = np.random.uniform(-wrg, wrg) * w\n",
    "    translation_matrix = np.array([[1, 0, tx],\n",
    "                                   [0, 1, ty],\n",
    "                                   [0, 0, 1]])\n",
    "\n",
    "    transform_matrix = translation_matrix  # no need to do offset\n",
    "    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n",
    "    return x\n",
    "\n",
    "\n",
    "def random_shear(x, intensity, row_axis=1, col_axis=2, channel_axis=0,\n",
    "                 fill_mode='nearest', cval=0.):\n",
    "    # Performs a random spatial shear of a Numpy image tensor.\n",
    "    shear = np.random.uniform(-intensity, intensity)\n",
    "    shear_matrix = np.array([[1, -np.sin(shear), 0],\n",
    "                             [0, np.cos(shear), 0],\n",
    "                             [0, 0, 1]])\n",
    "\n",
    "    h, w = x.shape[row_axis], x.shape[col_axis]\n",
    "    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)\n",
    "    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n",
    "    return x\n",
    "\n",
    "\n",
    "def random_zoom(x, zoom_range, row_axis=1, col_axis=2, channel_axis=0,\n",
    "                fill_mode='nearest', cval=0.):\n",
    "    # Performs a random spatial zoom of a Numpy image tensor.\n",
    "    if len(zoom_range) != 2:\n",
    "        raise ValueError('`zoom_range` should be a tuple or list of two floats. '\n",
    "                         'Received arg: ', zoom_range)\n",
    "\n",
    "    if zoom_range[0] == 1 and zoom_range[1] == 1:\n",
    "        zx, zy = 1, 1\n",
    "    else:\n",
    "        zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n",
    "    zoom_matrix = np.array([[zx, 0, 0],\n",
    "                            [0, zy, 0],\n",
    "                            [0, 0, 1]])\n",
    "\n",
    "    h, w = x.shape[row_axis], x.shape[col_axis]\n",
    "    transform_matrix = transform_matrix_offset_center(zoom_matrix, h, w)\n",
    "    x = apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n",
    "    return x\n",
    "\n",
    "\n",
    "def random_channel_shift(x, intensity, channel_axis=0):\n",
    "    x = np.rollaxis(x, channel_axis, 0)\n",
    "    min_x, max_x = np.min(x), np.max(x)\n",
    "    channel_images = [np.clip(x_channel + np.random.uniform(-intensity, intensity), min_x, max_x)\n",
    "                      for x_channel in x]\n",
    "    x = np.stack(channel_images, axis=0)\n",
    "    x = np.rollaxis(x, 0, channel_axis + 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def transform_matrix_offset_center(matrix, x, y):\n",
    "    o_x = float(x) / 2 + 0.5\n",
    "    o_y = float(y) / 2 + 0.5\n",
    "    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n",
    "    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n",
    "    return transform_matrix\n",
    "\n",
    "\n",
    "def apply_transform(x,\n",
    "                    transform_matrix,\n",
    "                    channel_axis=0,\n",
    "                    fill_mode='nearest',\n",
    "                    cval=0.):\n",
    "    # Apply the image transformation specified by a matrix.\n",
    "    x = np.rollaxis(x, channel_axis, 0)\n",
    "    final_affine_matrix = transform_matrix[:2, :2]\n",
    "    final_offset = transform_matrix[:2, 2]\n",
    "    channel_images = [scipy.ndimage.interpolation.affine_transform(\n",
    "        x_channel,\n",
    "        final_affine_matrix,\n",
    "        final_offset,\n",
    "        order=3,\n",
    "        mode=fill_mode,\n",
    "        cval=cval) for x_channel in x]\n",
    "    x = np.stack(channel_images, axis=0)\n",
    "    x = np.rollaxis(x, 0, channel_axis + 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def flip_axis(x, axis):\n",
    "    x = np.asarray(x).swapaxes(axis, 0)\n",
    "    x = x[::-1, ...]\n",
    "    x = x.swapaxes(0, axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def random_multiplication(x, range_mult):\n",
    "    x = x * np.random.uniform(range_mult[0], range_mult[1])\n",
    "    return x\n",
    "\n",
    "\n",
    "def random_transform(x, y):\n",
    "    \"\"\"Randomly augment a single image tensor.\n",
    "    # Arguments\n",
    "        x: 3D tensor, single image.\n",
    "        seed: random seed.\n",
    "    # Returns\n",
    "        A randomly transformed version of the input (same shape).\n",
    "    \"\"\"\n",
    "\n",
    "    rotation_range = 20\n",
    "    width_shift_range = 0.2\n",
    "    height_shift_range = 0.2\n",
    "    shear_range = 0.2\n",
    "    zoom_range = (0.2, 0.2)\n",
    "    horizontal_flip = True\n",
    "    vertical_flip = True\n",
    "    cval = 0\n",
    "    fill_mode = 'nearest'\n",
    "\n",
    "    # x is a single image, so it doesn't have image number at index 0\n",
    "    img_row_axis = 1\n",
    "    img_col_axis = 2\n",
    "    img_channel_axis = 0\n",
    "\n",
    "    # use composition of homographies\n",
    "    # to generate final transform that needs to be applied\n",
    "    if rotation_range:\n",
    "        theta = np.pi / 180 * \\\n",
    "            np.random.uniform(-rotation_range, rotation_range)\n",
    "    else:\n",
    "        theta = 0\n",
    "\n",
    "    if height_shift_range:\n",
    "        print(x.shape[img_row_axis])\n",
    "        tx = np.random.uniform(-height_shift_range, height_shift_range) * x.shape[img_row_axis]\n",
    "    else:\n",
    "        tx = 0\n",
    "\n",
    "    if width_shift_range:\n",
    "        ty = np.random.uniform(-width_shift_range, width_shift_range) * x.shape[img_col_axis]\n",
    "    else:\n",
    "        ty = 0\n",
    "\n",
    "    if shear_range:\n",
    "        shear = np.random.uniform(-shear_range, shear_range)\n",
    "    else:\n",
    "        shear = 0\n",
    "\n",
    "    if zoom_range[0] == 1 and zoom_range[1] == 1:\n",
    "        zx, zy = 1, 1\n",
    "    else:\n",
    "        zx = np.random.uniform(\n",
    "            zoom_range[0], zoom_range[1], 1)[0]\n",
    "        zy = zx.copy()\n",
    "\n",
    "    transform_matrix = None\n",
    "    if theta != 0:\n",
    "        rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                                    [np.sin(theta), np.cos(theta), 0],\n",
    "                                    [0, 0, 1]])\n",
    "        transform_matrix = rotation_matrix\n",
    "\n",
    "    if tx != 0 or ty != 0:\n",
    "        shift_matrix = np.array([[1, 0, tx],\n",
    "                                 [0, 1, ty],\n",
    "                                 [0, 0, 1]])\n",
    "        transform_matrix = shift_matrix if transform_matrix is None else np.dot(\n",
    "            transform_matrix, shift_matrix)\n",
    "\n",
    "    if shear != 0:\n",
    "        shear_matrix = np.array([[1, -np.sin(shear), 0],\n",
    "                                 [0, np.cos(shear), 0],\n",
    "                                 [0, 0, 1]])\n",
    "        transform_matrix = shear_matrix if transform_matrix is None else np.dot(\n",
    "            transform_matrix, shear_matrix)\n",
    "\n",
    "    if zx != 1 or zy != 1:\n",
    "        zoom_matrix = np.array([[zx, 0, 0],\n",
    "                                [0, zy, 0],\n",
    "                                [0, 0, 1]])\n",
    "        transform_matrix = zoom_matrix if transform_matrix is None else np.dot(\n",
    "            transform_matrix, zoom_matrix)\n",
    "\n",
    "    if transform_matrix is not None:\n",
    "        h, w = x.shape[img_row_axis], x.shape[img_col_axis]\n",
    "        transform_matrix = transform_matrix_offset_center(\n",
    "            transform_matrix, h, w)\n",
    "        x = apply_transform(x, transform_matrix, img_channel_axis,\n",
    "                            fill_mode=fill_mode, cval=cval)\n",
    "        y = apply_transform(y, transform_matrix, img_channel_axis,\n",
    "                            fill_mode=fill_mode, cval=cval)\n",
    "\n",
    "    if horizontal_flip:\n",
    "        if np.random.random() < 0.5:\n",
    "            x = flip_axis(x, img_col_axis)\n",
    "            y = flip_axis(y, img_col_axis)\n",
    "\n",
    "    if vertical_flip:\n",
    "        if np.random.random() < 0.5:\n",
    "            x = flip_axis(x, img_row_axis)\n",
    "            y = flip_axis(y, img_row_axis)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Generator\n",
    "\n",
    "import keras.utils\n",
    "import scipy.ndimage\n",
    "\n",
    "max_rotation_angle = 10\n",
    "\n",
    "class UltrasoundSegmentationBatchGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 x_set,\n",
    "                 y_set,\n",
    "                 batch_size,\n",
    "                 image_dimensions=(128, 128, 128),\n",
    "                 shuffle=True,\n",
    "                 n_channels=1,\n",
    "                 n_classes=2):\n",
    "        self.x = x_set\n",
    "        self.y = y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.image_dimensions = image_dimensions\n",
    "        self.shuffle = shuffle\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.number_of_images = self.x.shape[0]\n",
    "        self.indexes = np.arange(self.number_of_images)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return int(np.floor(self.number_of_images / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(self.number_of_images)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        x = np.empty((self.batch_size, *self.image_dimensions, self.n_channels))\n",
    "        y = np.empty((self.batch_size, *self.image_dimensions))\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            x[i,:,:,:,:] = self.x[batch_indexes[i],:,:,:,:]\n",
    "            y[i,:,:,:]= self.y[batch_indexes[i],:,:,:]\n",
    "        \n",
    "        # random_transform x and y\n",
    "        new_x = np.zeros(x.shape)\n",
    "        new_y = np.zeros(y.shape)\n",
    "\n",
    "        for idx in range(len(x)):\n",
    "            x_slice = x[idx, :, :, :]\n",
    "            x_crop = x_slice[:, :, :, 0]\n",
    "            y_slice = y[idx, :, :]\n",
    "            tr_x, tr_y = random_transform(x_crop, y_slice)\n",
    "            x_slice[:, :, :, 0] = tr_x\n",
    "            new_x[idx, :, :, :] = x_slice\n",
    "            new_y[idx, :, :] = tr_y\n",
    "\n",
    "        y_onehot = keras.utils.to_categorical(new_y, self.n_classes)\n",
    "\n",
    "        return new_x, y_onehot\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dilated output\n",
    "\n",
    "def dilateStack(segmentation_data, iterations):\n",
    "    return np.array([scipy.ndimage.binary_dilation(y, iterations=iterations) for y in segmentation_data])\n",
    "\n",
    "width = 128\n",
    "segmentation_dilated = dilateStack(segmentation_data[:, :, :, :, 0], width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you don't want dilation\n",
    "\n",
    "segmentation_dilated[:, :, :, :] = segmentation_data[:, :, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"batch_normalization_37/cond/Merge:0\", shape=(?, 2, 2, 2, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_38/cond/Merge:0\", shape=(?, 4, 4, 4, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_39/cond/Merge:0\", shape=(?, 8, 8, 8, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_40/cond/Merge:0\", shape=(?, 16, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_41/cond/Merge:0\", shape=(?, 32, 32, 32, 16), dtype=float32)\n",
      "Tensor(\"batch_normalization_42/cond/Merge:0\", shape=(?, 64, 64, 64, 8), dtype=float32)\n",
      "Tensor(\"conv3d_98/truediv:0\", shape=(?, 128, 128, 128, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "def nvidia_unet(patch_size=128, num_classes=num_classes):\n",
    "    input_ = Input((128, 128, 128, 1))\n",
    "    skips = []\n",
    "    output = input_\n",
    "    c = num_classes\n",
    "    \n",
    "    for shape, filters in zip([5, 3, 3, 3, 3, 3, 3], [8, 16, 32, 32, 32, 32, 32]):\n",
    "        skips.append(output)\n",
    "        #print(\"pre_skip\")\n",
    "        #print(output)\n",
    "        #print(shape)\n",
    "        output= Conv3D(filters, (3, 3, 3), strides=2, padding=\"same\", activation=\"relu\")(output)\n",
    "        #print(\"output3d\")\n",
    "        #print(output)\n",
    "    \n",
    "    # output = keras.layers.UpSampling3D(size=(1, 2, 2))(output)\n",
    "    for shape, filters in zip([4, 4, 4, 4, 4, 4, 4], [32, 32, 32, 32, 16, 8, 2]):\n",
    "        #print(output.shape)\n",
    "        output = keras.layers.UpSampling3D()(output)\n",
    "        #print(\"output2.0:\")\n",
    "        #print(output)\n",
    "        skip_output = skips.pop()\n",
    "        output = concatenate([output, skip_output], axis=4)\n",
    "\n",
    "        if filters != c:\n",
    "            activation = \"relu\"\n",
    "        else:\n",
    "            activation = \"softmax\"\n",
    "        output = Conv3D(filters, (3, 3, 3), activation=activation, padding=\"same\")(output)\n",
    "        if filters != c:\n",
    "            output = BatchNormalization(momentum=.9)(output)\n",
    "        \n",
    "        print(output)\n",
    "    \n",
    "    assert len(skips) == 0\n",
    "    return Model([input_], [output])\n",
    "\n",
    "model = nvidia_unet(128, num_classes)\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built with 376624 parameters\n"
     ]
    }
   ],
   "source": [
    "print(\"Model built with {} parameters\".format(model.count_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate decay = 0.0004995\n"
     ]
    }
   ],
   "source": [
    "max_learning_rate = 0.01\n",
    "min_learning_rate = 0.00001\n",
    "num_epochs = 20\n",
    "\n",
    "learning_rate_decay = (max_learning_rate - min_learning_rate) / num_epochs\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.adam(lr=max_learning_rate, decay=learning_rate_decay),\n",
    "               loss= \"binary_crossentropy\",\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"Learning rate decay = {}\".format(learning_rate_decay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "\n",
    "training_generator = UltrasoundSegmentationBatchGenerator(ultrasound_data, segmentation_dilated, batch_size)\n",
    "test_generator = UltrasoundSegmentationBatchGenerator(test_ultrasound_data, test_segmentation_data[:, :, :, :, 0], batch_size)\n",
    "\n",
    "training_time_start = datetime.datetime.now()\n",
    "\n",
    "training_log = model.fit_generator(training_generator,\n",
    "                                   validation_data=test_generator,\n",
    "                                   epochs=num_epochs,\n",
    "                                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_time_stop = datetime.datetime.now()\n",
    "print(\"Training started at: {}\".format(training_time_start))\n",
    "print(\"Training stopped at: {}\".format(training_time_stop))\n",
    "print(\"Total training time: {}\".format(training_time_stop-training_time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "saved_models_folder = 'saved_models'\n",
    "model_file_name = \"model_\" + timestamp + \".h5\"\n",
    "weights_file_path = os.path.join(saved_models_folder, model_file_name)\n",
    "\n",
    "model.save(weights_file_path)\n",
    "print(\"Model saved to: {}\".format(weights_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = load_model(weights_file_path)\n",
    "print(weights_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_model.predict(test_ultrasound_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training loss and accuracy curves over epochs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(training_log.history['loss'], 'bo--')\n",
    "plt.plot(training_log.history['val_loss'], 'ro-')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs (n)')\n",
    "plt.legend(['Training loss', 'Validation loss'])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(training_log.history['acc'], 'bo--')\n",
    "plt.plot(training_log.history['val_acc'], 'ro-')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs (n)')\n",
    "plt.legend(['Training accuracy', 'Validation accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-slice view code extracted and adapted from: https://www.datacamp.com/community/tutorials/matplotlib-3d-volumetric-data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def multi_slice_viewer(volume):\n",
    "    remove_keymap_conflicts({'j', 'k'})\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.volume = volume\n",
    "    ax.index = volume.shape[0] // 2\n",
    "    ax.imshow(volume[ax.index])\n",
    "    fig.canvas.mpl_connect('key_press_event', process_key)\n",
    "\n",
    "def process_key(event):\n",
    "    fig = event.canvas.figure\n",
    "    ax = fig.axes[0]\n",
    "    if event.key == 'j':\n",
    "        previous_slice(ax)\n",
    "    elif event.key == 'k':\n",
    "        next_slice(ax)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "def previous_slice(ax):\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index - 1) % volume.shape[0]  # wrap around using %\n",
    "    ax.images[0].set_array(volume[ax.index])\n",
    "\n",
    "def next_slice(ax):\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index + 1) % volume.shape[0]\n",
    "    ax.images[0].set_array(volume[ax.index])\n",
    "\n",
    "def remove_keymap_conflicts(new_keys_set):\n",
    "    for prop in plt.rcParams:\n",
    "        if prop.startswith('keymap.'):\n",
    "            keys = plt.rcParams[prop]\n",
    "            remove_list = set(keys) & new_keys_set\n",
    "            for key in remove_list:\n",
    "                keys.remove(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ultrasound\n",
    "ultrasound_img = test_ultrasound_data[0]\n",
    "print(ultrasound_img.shape)\n",
    "multi_slice_viewer(ultrasound_img[:, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation\n",
    "segmentation_img = test_segmentation_data[0]\n",
    "print(segmentation_img.shape)\n",
    "multi_slice_viewer(segmentation_img[:, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "predicted_img = y_pred[0]\n",
    "print(predicted_img.shape)\n",
    "multi_slice_viewer(predicted_img[:, :, :, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
