{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 24 ultrasound images and 24 segmentations\n"
     ]
    }
   ],
   "source": [
    "ultrasound_fullname = 'numpy_data/Stacked Arrays/stacked_image_array.npy'\n",
    "segmentation_fullname = 'numpy_data/Stacked Arrays/stacked_segmentation_array.npy'\n",
    "\n",
    "ultrasound_data = np.load(ultrasound_fullname)\n",
    "segmentation_data = np.load(segmentation_fullname)\n",
    "\n",
    "num_ultrasound = ultrasound_data.shape[0]\n",
    "num_segmentation = segmentation_data.shape[0]\n",
    "\n",
    "print(\"\\nFound {} ultrasound images and {} segmentations\".format(num_ultrasound, num_segmentation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test ultrasound from: numpy_data/Stacked Arrays/test_image_array.npy\n",
      "Reading test segmentation from : numpy_data/Stacked Arrays/test_segmentation_array.npy\n",
      "\n",
      "Found 6 test ultrasound images and 6 segmentations\n"
     ]
    }
   ],
   "source": [
    "test_ultrasound_fullname = 'numpy_data/Stacked Arrays/test_image_array.npy'\n",
    "test_segmentation_fullname = 'numpy_data/Stacked Arrays/test_segmentation_array.npy'\n",
    "\n",
    "print(\"Reading test ultrasound from: {}\".format(test_ultrasound_fullname))\n",
    "print(\"Reading test segmentation from : {}\".format(test_segmentation_fullname))\n",
    "\n",
    "test_ultrasound_data = np.load(test_ultrasound_fullname)\n",
    "test_segmentation_data = np.load(test_segmentation_fullname)\n",
    "\n",
    "num_test_ultrasound = test_ultrasound_data.shape[0]\n",
    "num_test_segmentation = test_segmentation_data.shape[0]\n",
    "\n",
    "print(\"\\nFound {} test ultrasound images and {} segmentations\".format(num_test_ultrasound, num_test_segmentation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-slice view code extracted and adapted from: https://www.datacamp.com/community/tutorials/matplotlib-3d-volumetric-data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def multi_slice_viewer(feats, anns = None, preds = None, num_classes = 4):\n",
    "    # Plot feats, anns, predictions in multi-slice-view\n",
    "    # Note this feats OR feats + anns OR feats + anns + preds\n",
    "    if anns is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.volume = feats\n",
    "        ax.index = feats.shape[-1] // 2\n",
    "        ax.imshow(feats[:, :, ax.index],  cmap='bone')\n",
    "        fig.canvas.mpl_connect('key_press_event', process_key)\n",
    "    else:\n",
    "        if preds is None:\n",
    "            fig, axarr = plt.subplots(1, 2)\n",
    "            plt.tight_layout()\n",
    "            axarr[0].volume = feats\n",
    "            axarr[0].index = 0\n",
    "            axarr[0].imshow(feats[:, :, axarr[0].index],  cmap='bone')\n",
    "            axarr[0].set_title('Scans')\n",
    "            axarr[1].volume = anns\n",
    "            axarr[1].index = 0\n",
    "            axarr[1].imshow(anns[:, :, axarr[1].index],  cmap='bone', vmin = 0, vmax = num_classes)\n",
    "            axarr[1].set_title('Annotations')\n",
    "            fig.canvas.mpl_connect('key_press_event', process_key)\n",
    "        else:\n",
    "            fig, axarr = plt.subplots(1, 3)\n",
    "            plt.tight_layout()\n",
    "            axarr[0].volume = feats\n",
    "            axarr[0].index = 0\n",
    "            axarr[0].imshow(feats[:, :, axarr[0].index],  cmap='bone')\n",
    "            axarr[0].set_title('Scans')\n",
    "            axarr[1].volume = anns\n",
    "            axarr[1].index = 0\n",
    "            axarr[1].imshow(anns[:, :, axarr[1].index],  cmap='bone', vmin = 0, vmax = num_classes)\n",
    "            axarr[1].set_title('Annotations')\n",
    "            axarr[2].volume = preds\n",
    "            axarr[2].index = 0\n",
    "            axarr[2].imshow(preds[:, :, axarr[2].index],  cmap='bone', vmin = 0, vmax = num_classes)\n",
    "            axarr[2].set_title('Predictions')\n",
    "            fig.canvas.mpl_connect('key_press_event', process_key)\n",
    "\n",
    "def process_key(event):\n",
    "    # Process key_press events\n",
    "    fig = event.canvas.figure\n",
    "    if event.key == 'j':\n",
    "        for ax in fig.axes: \n",
    "            previous_slice(ax)\n",
    "    elif event.key == 'k':\n",
    "        for ax in fig.axes: \n",
    "            next_slice(ax)            \n",
    "    fig.canvas.draw()\n",
    "\n",
    "def previous_slice(ax):\n",
    "    \"\"\"Go to the previous slice.\"\"\"\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index - 1) % volume.shape[-1]  # wrap around using %\n",
    "    ax.images[0].set_array(volume[:, :, ax.index])\n",
    "\n",
    "def next_slice(ax):\n",
    "    \"\"\"Go to the next slice.\"\"\"\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index + 1) % volume.shape[-1]\n",
    "    ax.images[0].set_array(volume[:, :, ax.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_slice_viewer(ultrasound_data[0][0], segmentation_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Generator\n",
    "\n",
    "import keras.utils\n",
    "import scipy.ndimage\n",
    "\n",
    "max_rotation_angle = 10\n",
    "\n",
    "class UltrasoundSegmentationBatchGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 x_set,\n",
    "                 y_set,\n",
    "                 batch_size,\n",
    "                 image_dimensions=(128, 128, 128),\n",
    "                 shuffle=True,\n",
    "                 n_channels=1,\n",
    "                 n_classes=2):\n",
    "        self.x = x_set\n",
    "        self.y = y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.image_dimensions = image_dimensions\n",
    "        self.shuffle = shuffle\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.number_of_images = self.x.shape[0]\n",
    "        self.indexes = np.arange(self.number_of_images)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return int(np.floor(self.number_of_images / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(self.number_of_images)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        x = np.empty((self.batch_size, *self.image_dimensions, self.n_channels))\n",
    "        y = np.empty((self.batch_size, *self.image_dimensions))\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            x[i,:,:,:,:] = self.x[batch_indexes[i],:,:,:,:]\n",
    "            y[i,:,:,:]= self.y[batch_indexes[i],:,:,:]\n",
    "\n",
    "            \n",
    "        y_onehot = keras.utils.to_categorical(y, self.n_classes)\n",
    "\n",
    "        return x, y_onehot\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dilated output\n",
    "\n",
    "def dilateStack(segmentation_data, iterations):\n",
    "    return np.array([scipy.ndimage.binary_dilation(y, iterations=iterations) for y in segmentation_data])\n",
    "\n",
    "width = 128\n",
    "segmentation_dilated = dilateStack(segmentation_data[:, :, :, :, 0], width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you don't want dilation\n",
    "\n",
    "segmentation_dilated[:, :, :, :] = segmentation_data[:, :, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\z.hu\\AppData\\Local\\Continuum\\anaconda3\\envs\\brachyTest\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"batch_normalization_1/cond/Merge:0\", shape=(?, 2, 4, 4, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_2/cond/Merge:0\", shape=(?, 4, 8, 8, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_3/cond/Merge:0\", shape=(?, 8, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_4/cond/Merge:0\", shape=(?, 16, 32, 32, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_5/cond/Merge:0\", shape=(?, 32, 64, 64, 16), dtype=float32)\n",
      "Tensor(\"batch_normalization_6/cond/Merge:0\", shape=(?, 64, 128, 128, 8), dtype=float32)\n",
      "Tensor(\"conv3d_14/truediv:0\", shape=(?, 128, 256, 256, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "def nvidia_unet(patch_size=128, num_classes=num_classes):\n",
    "    input_ = Input((128, 128, 128, 1))\n",
    "    skips = []\n",
    "    output = input_\n",
    "    c = num_classes\n",
    "    \n",
    "    for shape, filters in zip([5, 3, 3, 3, 3, 3, 3], [8, 16, 32, 32, 32, 32, 32]):\n",
    "        skips.append(output)\n",
    "        #print(\"pre_skip\")\n",
    "        #print(output)\n",
    "        #print(shape)\n",
    "        output= Conv3D(filters, (shape, shape, shape), strides=2, padding=\"same\", activation=\"relu\")(output)\n",
    "        #print(\"output3d\")\n",
    "        #print(output)\n",
    "    \n",
    "    # output = keras.layers.UpSampling3D(size=(1, 2, 2))(output)\n",
    "    for shape, filters in zip([4, 4, 4, 4, 4, 4, 4], [32, 32, 32, 32, 16, 8, 2]):\n",
    "        #print(output.shape)\n",
    "        output = keras.layers.UpSampling3D()(output)\n",
    "        #print(\"output2.0:\")\n",
    "        #print(output)\n",
    "        skip_output = skips.pop()\n",
    "        output = concatenate([output, skip_output], axis=4)\n",
    "\n",
    "        if filters != c:\n",
    "            activation = \"relu\"\n",
    "        else:\n",
    "            activation = \"softmax\"\n",
    "        output = Conv3D(filters, (shape, shape, shape), activation=activation, padding=\"same\")(output)\n",
    "        if filters != c:\n",
    "            output = BatchNormalization(momentum=.9)(output)\n",
    "        \n",
    "        print(output)\n",
    "    \n",
    "    assert len(skips) == 0\n",
    "    return Model([input_], [output])\n",
    "\n",
    "model = nvidia_unet(128, num_classes)\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built with 716698 parameters\n"
     ]
    }
   ],
   "source": [
    "print(\"Model built with {} parameters\".format(model.count_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate decay = 4.95e-05\n"
     ]
    }
   ],
   "source": [
    "max_learning_rate = 0.001\n",
    "min_learning_rate = 0.00001\n",
    "num_epochs = 20\n",
    "\n",
    "learning_rate_decay = (max_learning_rate - min_learning_rate) / num_epochs\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.adam(lr=max_learning_rate, decay=learning_rate_decay),\n",
    "               loss= \"binary_crossentropy\",\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"Learning rate decay = {}\".format(learning_rate_decay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\z.hu\\AppData\\Local\\Continuum\\anaconda3\\envs\\brachyTest\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\z.hu\\AppData\\Local\\Continuum\\anaconda3\\envs\\brachyTest\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "training_generator = UltrasoundSegmentationBatchGenerator(ultrasound_data, segmentation_dilated, batch_size)\n",
    "test_generator = UltrasoundSegmentationBatchGenerator(test_ultrasound_data, test_segmentation_data[:, :, :, :, 0], batch_size)\n",
    "\n",
    "training_time_start = datetime.datetime.now()\n",
    "\n",
    "training_log = model.fit_generator(training_generator,\n",
    "                                   validation_data=test_generator,\n",
    "                                   epochs=num_epochs,\n",
    "                                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_time_stop = datetime.datetime.now()\n",
    "print(\"Training started at: {}\".format(training_time_start))\n",
    "print(\"Training stopped at: {}\".format(training_time_stop))\n",
    "print(\"Total training time: {}\".format(training_time_stop-training_time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_ultrasound_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
