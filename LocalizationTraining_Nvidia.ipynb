{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 6 ultrasound images and 6 segmentations\n"
     ]
    }
   ],
   "source": [
    "ultrasound_fullname = 'numpy_data/Stacked Arrays/stacked_image_array.npy'\n",
    "segmentation_fullname = 'numpy_data/Stacked Arrays/stacked_segmentation_array.npy'\n",
    "\n",
    "ultrasound_data = np.load(ultrasound_fullname)\n",
    "segmentation_data = np.load(segmentation_fullname)\n",
    "\n",
    "num_ultrasound = ultrasound_data.shape[0]\n",
    "num_segmentation = segmentation_data.shape[0]\n",
    "\n",
    "print(\"\\nFound {} ultrasound images and {} segmentations\".format(num_ultrasound, num_segmentation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test ultrasound from: numpy_data/Stacked Arrays/test_image_array.npy\n",
      "Reading test segmentation from : numpy_data/Stacked Arrays/test_segmentation_array.npy\n",
      "\n",
      "Found 6 test ultrasound images and 6 segmentations\n"
     ]
    }
   ],
   "source": [
    "test_ultrasound_fullname = 'numpy_data/Stacked Arrays/test_image_array.npy'\n",
    "test_segmentation_fullname = 'numpy_data/Stacked Arrays/test_segmentation_array.npy'\n",
    "\n",
    "print(\"Reading test ultrasound from: {}\".format(test_ultrasound_fullname))\n",
    "print(\"Reading test segmentation from : {}\".format(test_segmentation_fullname))\n",
    "\n",
    "test_ultrasound_data = np.load(test_ultrasound_fullname)\n",
    "test_segmentation_data = np.load(test_segmentation_fullname)\n",
    "\n",
    "num_test_ultrasound = test_ultrasound_data.shape[0]\n",
    "num_test_segmentation = test_segmentation_data.shape[0]\n",
    "\n",
    "print(\"\\nFound {} test ultrasound images and {} segmentations\".format(num_test_ultrasound, num_test_segmentation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-slice view code extracted and adapted from: https://www.datacamp.com/community/tutorials/matplotlib-3d-volumetric-data\n",
    "\n",
    "def multi_slice_viewer(volume):\n",
    "    remove_keymap_conflicts({'j', 'k'})\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.volume = volume\n",
    "    ax.index = volume.shape[0] // 2\n",
    "    ax.imshow(volume[ax.index])\n",
    "    fig.canvas.mpl_connect('key_press_event', process_key)\n",
    "\n",
    "def process_key(event):\n",
    "    fig = event.canvas.figure\n",
    "    ax = fig.axes[0]\n",
    "    if event.key == 'j':\n",
    "        previous_slice(ax)\n",
    "    elif event.key == 'k':\n",
    "        next_slice(ax)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "def previous_slice(ax):\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index - 1) % volume.shape[0]  # wrap around using %\n",
    "    ax.images[0].set_array(volume[ax.index])\n",
    "\n",
    "def next_slice(ax):\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index + 1) % volume.shape[0]\n",
    "    ax.images[0].set_array(volume[ax.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Generator\n",
    "\n",
    "import keras.utils\n",
    "import scipy.ndimage\n",
    "\n",
    "max_rotation_angle = 10\n",
    "\n",
    "class UltrasoundSegmentationBatchGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 x_set,\n",
    "                 y_set,\n",
    "                 batch_size,\n",
    "                 image_dimensions=(128, 128, 128),\n",
    "                 shuffle=True,\n",
    "                 n_channels=1,\n",
    "                 n_classes=2):\n",
    "        self.x = x_set\n",
    "        self.y = y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.image_dimensions = image_dimensions\n",
    "        self.shuffle = shuffle\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.number_of_images = self.x.shape[0]\n",
    "        self.indexes = np.arange(self.number_of_images)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return int(np.floor(self.number_of_images / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(self.number_of_images)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        x = np.empty((self.batch_size, *self.image_dimensions, self.n_channels))\n",
    "        y = np.empty((self.batch_size, *self.image_dimensions))\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            x[i,:,:,:,:] = self.x[batch_indexes[i],:,:,:,:]\n",
    "            y[i,:,:,:]= self.y[batch_indexes[i],:,:,:]\n",
    "\n",
    "            \n",
    "        y_onehot = keras.utils.to_categorical(y, self.n_classes)\n",
    "\n",
    "        return x, y_onehot\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dilated output\n",
    "\n",
    "def dilateStack(segmentation_data, iterations):\n",
    "    return np.array([scipy.ndimage.binary_dilation(y, iterations=iterations) for y in segmentation_data])\n",
    "\n",
    "width = 128\n",
    "segmentation_dilated = dilateStack(segmentation_data[:, :, :, :, 0], width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you don't want dilation\n",
    "\n",
    "segmentation_dilated[:, :, :, :] = segmentation_data[:, :, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"batch_normalization_7/cond/Merge:0\", shape=(?, 2, 2, 2, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_8/cond/Merge:0\", shape=(?, 4, 4, 4, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_9/cond/Merge:0\", shape=(?, 8, 8, 8, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_10/cond/Merge:0\", shape=(?, 16, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_11/cond/Merge:0\", shape=(?, 32, 32, 32, 16), dtype=float32)\n",
      "Tensor(\"batch_normalization_12/cond/Merge:0\", shape=(?, 64, 64, 64, 8), dtype=float32)\n",
      "Tensor(\"conv3d_28/truediv:0\", shape=(?, 128, 128, 128, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "def nvidia_unet(patch_size=128, num_classes=num_classes):\n",
    "    input_ = Input((128, 128, 128, 1))\n",
    "    skips = []\n",
    "    output = input_\n",
    "    c = num_classes\n",
    "    \n",
    "    for shape, filters in zip([5, 3, 3, 3, 3, 3, 3], [8, 16, 32, 32, 32, 32, 32]):\n",
    "        skips.append(output)\n",
    "        #print(\"pre_skip\")\n",
    "        #print(output)\n",
    "        #print(shape)\n",
    "        output= Conv3D(filters, (shape, shape, shape), strides=2, padding=\"same\", activation=\"relu\")(output)\n",
    "        #print(\"output3d\")\n",
    "        #print(output)\n",
    "    \n",
    "    # output = keras.layers.UpSampling3D(size=(1, 2, 2))(output)\n",
    "    for shape, filters in zip([4, 4, 4, 4, 4, 4, 4], [32, 32, 32, 32, 16, 8, 2]):\n",
    "        #print(output.shape)\n",
    "        output = keras.layers.UpSampling3D()(output)\n",
    "        #print(\"output2.0:\")\n",
    "        #print(output)\n",
    "        skip_output = skips.pop()\n",
    "        output = concatenate([output, skip_output], axis=4)\n",
    "\n",
    "        if filters != c:\n",
    "            activation = \"relu\"\n",
    "        else:\n",
    "            activation = \"softmax\"\n",
    "        output = Conv3D(filters, (shape, shape, shape), activation=activation, padding=\"same\")(output)\n",
    "        if filters != c:\n",
    "            output = BatchNormalization(momentum=.9)(output)\n",
    "        \n",
    "        print(output)\n",
    "    \n",
    "    assert len(skips) == 0\n",
    "    return Model([input_], [output])\n",
    "\n",
    "model = nvidia_unet(128, num_classes)\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built with 716698 parameters\n"
     ]
    }
   ],
   "source": [
    "print(\"Model built with {} parameters\".format(model.count_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate decay = 4.95e-05\n"
     ]
    }
   ],
   "source": [
    "max_learning_rate = 0.001\n",
    "min_learning_rate = 0.00001\n",
    "num_epochs = 20\n",
    "\n",
    "learning_rate_decay = (max_learning_rate - min_learning_rate) / num_epochs\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.adam(lr=max_learning_rate, decay=learning_rate_decay),\n",
    "               loss= \"binary_crossentropy\",\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"Learning rate decay = {}\".format(learning_rate_decay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\z.hu\\AppData\\Local\\Continuum\\anaconda3\\envs\\brachyTest\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "training_generator = UltrasoundSegmentationBatchGenerator(ultrasound_data, segmentation_dilated, batch_size)\n",
    "test_generator = UltrasoundSegmentationBatchGenerator(test_ultrasound_data, test_segmentation_data[:, :, :, :, 0], batch_size)\n",
    "\n",
    "training_time_start = datetime.datetime.now()\n",
    "\n",
    "training_log = model.fit_generator(training_generator,\n",
    "                                   validation_data=test_generator,\n",
    "                                   epochs=num_epochs,\n",
    "                                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_time_stop = datetime.datetime.now()\n",
    "print(\"Training started at: {}\".format(training_time_start))\n",
    "print(\"Training stopped at: {}\".format(training_time_stop))\n",
    "print(\"Total training time: {}\".format(training_time_stop-training_time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_ultrasound_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
